{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will define the basic data sources.\n",
    "\n",
    "Unless you are changing how the data is fetched or processed, you don't need to run this notebook. When this notebook is run, data source creation will be serialized to the catalog. Once `datasources.json` catalog file has been created, you won't need to run this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic utility functions\n",
    "import logging\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easydata Imports\n",
    "from src import paths\n",
    "from src.log import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Data Source\n",
    "This data source encapsulates the data at:\n",
    "    https://pages.semanticscholar.org/coronavirus-research\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_date = '20200319'\n",
    "ds_name = f'covid_nlp_{extract_date}'\n",
    "dsrc = DataSource(ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_txt = '''COVID DATASET LICENSE AGREEMENT\n",
    "By accessing, downloading or otherwise using any Journals, Articles, Metadata, Abstracts,\n",
    "Full-Texts or any other content types provided in the COVID-19 Open Research Dataset (CORD-19)\n",
    "Database (the “Data”), You expressly acknowledge and agree to the following:\n",
    "\n",
    "* AI2 grants to You a worldwide, perpetual, non-exclusive, non-transferable\n",
    "  license to use and make derivatives of the Data for text and data mining only.\n",
    "\n",
    "* AI2 warrants that it has the right to make the Data available to You as\n",
    "  provided for in and subject to this Agreement and in accordance with applicable law. \n",
    "  EXCEPT FOR THE LIMITED WARRANTY IN THIS SECTION, THE DATA IS PROVIDED “AS IS”, WITHOUT ANY\n",
    "  WARRANTIES OF ANY KIND. \n",
    "\n",
    "* You agree to comply with all applicable local, state, national, and international laws\n",
    "  and regulations with respect to AI2’s license and Youruse of the Data.\n",
    "\n",
    "* Data provided by AI2 is from copyrighted sources of the respective copyright holders.\n",
    "  You are solely responsible for Your and Your users’ compliance with any copyright, patent\n",
    "  or trademark restrictions and are referred to the copyright, patent or trademark notices\n",
    "  appearing in the original sources, all of which are hereby incorporated by reference.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_txt = '''COVID-19 Open Research Dataset (CORD-19)\n",
    "Participate in the CORD-19 Challenge\n",
    "\n",
    "Kaggle is hosting the COVID-19 Open Research Dataset Challenge, a\n",
    "series of important questions designed to inspire the community\n",
    "to use CORD-19 to find new insights about the COVID-19 pandemic\n",
    "including the natural history, transmission, and diagnostics for\n",
    "the virus, management measures at the human-animal interface,\n",
    "lessons from previous epidemiological studies, and more.\n",
    "Download CORD-19\n",
    "\n",
    "By downloading this dataset you are agreeing to the Dataset\n",
    "License. Specific licensing information for individual articles\n",
    "in the dataset is available in the metadata file.\n",
    "\n",
    "Additional licensing information is available on the PMC website,\n",
    "medRxiv website and bioRxiv website.\n",
    "\n",
    "Latest release contains papers up until 2020-03-13 with over\n",
    "13,000 full text articles.\n",
    "\n",
    "Download here:\n",
    "\n",
    "    Commercial use subset (includes PMC content) -- 9000 papers, 186Mb\n",
    "    Non-commercial use subset (includes PMC content) -- 1973 papers, 36Mb\n",
    "    PMC custom license subset -- 1426 papers, 19Mb\n",
    "    bioRxiv/medRxiv subset (pre-prints that are not peer reviewed) -- 803 papers, 13Mb\n",
    "    Metadata file -- 47Mb\n",
    "    Readme\n",
    "\n",
    "Each paper is represented as a single JSON object. The schema is\n",
    "available here.\n",
    "\n",
    "Description:\n",
    "\n",
    "The dataset contains all COVID-19 and coronavirus-related\n",
    "research (e.g. SARS, MERS, etc.) from the following sources:\n",
    "\n",
    "* PubMed's PMC open access corpus using this query\n",
    "  (COVID-19 and coronavirus research)\n",
    "* Additional COVID-19 research articles from a corpus\n",
    "  maintained by the WHO\n",
    "* bioRxiv and medRxiv pre-prints using the same query\n",
    "  as PMC (COVID-19 and coronavirus research)\n",
    "\n",
    "We also provide a comprehensive metadata file of 29,000\n",
    "coronavirus and COVID-19 research articles with links to PubMed,\n",
    "Microsoft Academic and the WHO COVID-19 database of\n",
    "publications (includes articles without open access full text).\n",
    "\n",
    "We recommend using metadata from the comprehensive file when\n",
    "available, instead of parsed metadata in the dataset. Please note\n",
    "the dataset may contain multiple entries for individual PMC IDs\n",
    "in cases when supplementary materials are available.\n",
    "\n",
    "This repository is linked to the WHO database of publications on\n",
    "coronavirus disease and other resources, such as Microsoft\n",
    "Academic Graph, PubMed, and Semantic Scholar. A coalition\n",
    "including the Chan Zuckerberg Initiative, Georgetown University’s\n",
    "Center for Security and Emerging Technology, Microsoft Research,\n",
    "and the National Library of Medicine of the National Institutes\n",
    "of Health came together to provide this service. We also thank\n",
    "and acknowledge Unpaywall for providing open access license\n",
    "information for portions of the dataset.\n",
    "\n",
    "Citation:\n",
    "\n",
    "When including CORD-19 data in a publication or redistribution,\n",
    "please cite the dataset as follows:\n",
    "\n",
    "In bibliography:\n",
    "\n",
    "COVID-19 Open Research Dataset (CORD-19). 2020. Version 2020-03-13. \n",
    "Retrieved from https://pages.semanticscholar.org/coronavirus-research. \n",
    "Accessed YYYY-MM-DD. doi:10.5281/zenodo.3715506\n",
    "\n",
    "In text:\n",
    "\n",
    "(CORD-19, 2020)\n",
    "\n",
    "The Allen Institute for AI and particularly the Semantic Scholar\n",
    "team will continue to provide updates to this dataset as the\n",
    "situation evolves and new research is released.\n",
    "\n",
    "Contribute to CORD-19\n",
    "\n",
    "To maximize impact and increase full text available to the global\n",
    "research community, we are actively encouraging publishers to\n",
    "make their research content openly available for AI projects like\n",
    "this that benefit the common good. If you’re a publisher\n",
    "interested in contributing to the CORD-19 corpus, please contact\n",
    "partnerships@allenai.org.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.add_metadata(contents=license_txt, kind='LICENSE')\n",
    "dsrc.add_metadata(contents=readme_txt, kind='DESCR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.add_url('https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-03-13/comm_use_subset.tar.gz',\n",
    "             name='commercial use subset')\n",
    "\n",
    "dsrc.add_url('https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-03-13/noncomm_use_subset.tar.gz',\n",
    "             name='non-commmercial use subset')\n",
    "dsrc.add_url('https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-03-13/pmc_custom_license.tar.gz',\n",
    "             name='PMC custom license')\n",
    "dsrc.add_url('https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-03-13/biorxiv_medrxiv.tar.gz',\n",
    "             name='bioRxiv and medRxiv')\n",
    "dsrc.add_url('https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-03-13/all_sources_metadata_2020-03-13.csv',\n",
    "             name='metadata file')\n",
    "dsrc.add_url('https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/2020-03-13/all_sources_metadata_2020-03-13.readme',\n",
    "             name='readme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform to a DataSet\n",
    "\n",
    "Use the process function that we created in local data that adds filename data to the dataframe created from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.localdata import process_covid_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.parse_function = process_covid_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dsrc.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_datasource(dsrc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the datasource and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow.add_datasource(dsrc)\n",
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = paths['catalog_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $c/datasources.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a dummy transformer to turn this into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workflow.add_transformer(from_datasource='covid_nlp_20200319', output_dataset='covid_nlp_20200319')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
